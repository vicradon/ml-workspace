{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "3d3664fc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vocabulary size: 8\n",
                        "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
                        " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
                        " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
                        " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
                        " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
                        " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
                        " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
                        " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "from torch import nn\n",
                "from torch import optim\n",
                "\n",
                "sentence = \"The quick brown fox jumped over the lazy dog\"\n",
                "\n",
                "unique_words = sorted(list(set([word.lower() for word in sentence.split()])))\n",
                "length = len(unique_words)\n",
                "word_to_index = {word: i for i, word in enumerate(unique_words)}\n",
                "index_to_word = {i: word for i, word in enumerate(unique_words)}\n",
                "\n",
                "vectors = []\n",
                "vector_template = np.zeros(length)\n",
                "\n",
                "for index, word in enumerate(unique_words):\n",
                "    vector = vector_template.copy()\n",
                "    vector[index] = 1\n",
                "    vectors.append(vector)\n",
                "\n",
                "vectors = np.array(vectors)\n",
                "print(f\"Vocabulary size: {length}\")\n",
                "print(vectors)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "d19e98bc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 100, Loss: 0.0933\n",
                        "Epoch 200, Loss: 0.0108\n",
                        "Epoch 300, Loss: 0.0030\n",
                        "Epoch 400, Loss: 0.0013\n",
                        "Epoch 500, Loss: 0.0007\n"
                    ]
                }
            ],
            "source": [
                "words = [word.lower() for word in sentence.split()]\n",
                "completions = [\n",
                "    {\n",
                "        \"x\": \"the quick\",\n",
                "        \"y\": \"brown\"\n",
                "    },\n",
                "    {\n",
                "        \"x\": \"quick brown\",\n",
                "        \"y\": \"fox\"\n",
                "    }\n",
                "]\n",
                "\n",
                "for i in range(2, len(words) - 2):\n",
                "    completions.append({\n",
                "        \"x\": f\"{words[i]} {words[i+1]}\",\n",
                "        \"y\": words[i+2]\n",
                "    })\n",
                "\n",
                "def get_input_tensor(text):\n",
                "    words = text.lower().split()\n",
                "    # Concatenate vectors for the two input words\n",
                "    # Each word vector is size 8 (length of vocab)\n",
                "    # Resulting tensor size is 16\n",
                "    input_vector = []\n",
                "    for word in words:\n",
                "        idx = word_to_index[word]\n",
                "        input_vector.extend(vectors[idx])\n",
                "    return torch.tensor(input_vector, dtype=torch.float32).unsqueeze(0) # Add batch dimension\n",
                "\n",
                "def get_target_index_tensor(target_word):\n",
                "    # CrossEntropyLoss expects class index, not one-hot vector\n",
                "    idx = word_to_index[target_word.lower()]\n",
                "    return torch.tensor([idx], dtype=torch.long)\n",
                "\n",
                "network = nn.Sequential(\n",
                "    nn.Linear(16, 8), # input layer\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8), # hidden layer 1\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8) \n",
                ")\n",
                "\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
                "\n",
                "epochs = 500\n",
                "for epoch in range(epochs):\n",
                "    total_loss = 0\n",
                "    for completion in completions:\n",
                "        input_tensor = get_input_tensor(completion[\"x\"])\n",
                "        target_tensor = get_target_index_tensor(completion[\"y\"])\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        output = network(input_tensor)\n",
                "        \n",
                "        loss = criterion(output, target_tensor)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "        \n",
                "    if (epoch + 1) % 100 == 0:\n",
                "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "083a2582",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'torch.nn.modules.container.Sequential'>\n"
                    ]
                }
            ],
            "source": [
                "print(type(network))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "prediction-cell",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predictions:\n",
                        "jumped over -> the\n",
                        "the quick -> brown\n",
                        "fox jumped -> over\n",
                        "over the -> lazy\n",
                        "\n",
                        "============ full sentence prediction ============\n",
                        "0 the quick\n",
                        "1 quick brown\n",
                        "2 brown fox\n",
                        "3 fox jumped\n",
                        "4 jumped over\n",
                        "5 over the\n",
                        "6 the lazy\n",
                        "the quick brown fox jumped over the lazy dog\n"
                    ]
                }
            ],
            "source": [
                "def predict(text):\n",
                "    network.eval()\n",
                "    with torch.no_grad():\n",
                "        input_tensor = get_input_tensor(text)\n",
                "        output_logits = network(input_tensor)\n",
                "        probabilities = torch.softmax(output_logits, dim=1)\n",
                "        predicted_idx = torch.argmax(probabilities).item()\n",
                "        return index_to_word[predicted_idx]\n",
                "\n",
                "# Test predictions\n",
                "print(\"Predictions:\")\n",
                "print(f\"jumped over -> {predict('jumped over')}\")\n",
                "print(f\"the quick -> {predict('the quick')}\")\n",
                "print(f\"fox jumped -> {predict('fox jumped')}\")\n",
                "print(f\"over the -> {predict('over the')}\")\n",
                "\n",
                "\n",
                "\n",
                "# Full sentence prediction\n",
                "print(\"\\n============ full sentence prediction ============\")\n",
                "full_sentence = \"the quick\"\n",
                "start = full_sentence\n",
                "\n",
                "for i in range(7):\n",
                "    print(i, start)\n",
                "    prediction = predict(start)\n",
                "    full_sentence = \" \".join(full_sentence.split() + [prediction])\n",
                "    start = \" \".join(full_sentence.split()[-2:])\n",
                "\n",
                "print(full_sentence)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "7da470a8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "9\n"
                    ]
                }
            ],
            "source": [
                "print(len(network))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "embeddings-cell",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Embedding Weights shape: (8, 16)\n",
                        "Columns 0-7 correspond to the first word's embedding.\n",
                        "Columns 8-15 correspond to the second word's embedding.\n",
                        "\n",
                        "Example: Embedding for 'fox' (index 3)\n",
                        "Fox index: 2\n",
                        "Fox embedding when in position 1:\n",
                        "[-0.3145869  -0.04705364 -0.19518547  1.2083002  -0.08225289  1.8026392\n",
                        " -0.5869664   1.8209193 ]\n",
                        "Fox embedding when in position 2:\n",
                        "[ 0.6153387   0.22792171 -0.04185193  0.06262119 -0.09889055 -0.03212455\n",
                        "  0.44432968 -0.07397515]\n"
                    ]
                }
            ],
            "source": [
                "# Visualizing the Embedding Vectors\n",
                "# Since we use One-Hot encoding feeding into a Linear layer, \n",
                "# the weights of the input layer ACT as the embeddings.\n",
                "# Input size is 16 (8 dimensions for first word, 8 for second word).\n",
                "\n",
                "\n",
                "input_layer = network[0]\n",
                "weights = input_layer.weight.detach().numpy() # Shape: (8 hidden_units, 16 inputs)\n",
                "\n",
                "# Transpose to see inputs as rows: Shape (16, 8)\n",
                "weights_T = weights.T\n",
                "\n",
                "print(\"Embedding Weights shape:\", weights.shape)\n",
                "print(\"Columns 0-7 correspond to the first word's embedding.\")\n",
                "print(\"Columns 8-15 correspond to the second word's embedding.\")\n",
                "\n",
                "print(\"\\nExample: Embedding for 'fox' (index 3)\")\n",
                "# Let's say 'fox' is at index 3.\n",
                "fox_idx = word_to_index['fox']\n",
                "print(f\"Fox index: {fox_idx}\")\n",
                "\n",
                "print(\"Fox embedding when in position 1:\")\n",
                "print(weights[:, fox_idx])\n",
                "\n",
                "print(\"Fox embedding when in position 2:\")\n",
                "print(weights[:, fox_idx + 8])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "bb0a5c1f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[torch.onnx] Obtain model graph for `Sequential([...]` with `torch.export.export(..., strict=False)`...\n",
                        "[torch.onnx] Obtain model graph for `Sequential([...]` with `torch.export.export(..., strict=False)`... ✅\n",
                        "[torch.onnx] Run decomposition...\n",
                        "[torch.onnx] Run decomposition... ✅\n",
                        "[torch.onnx] Translate the graph into ONNX...\n",
                        "[torch.onnx] Translate the graph into ONNX... ✅\n"
                    ]
                }
            ],
            "source": [
                "example_input = torch.randn(1, 16)\n",
                "onnx_program = torch.onnx.export(network, example_input)\n",
                "onnx_program.save(\"fox_word_predictor.onnx\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "49ede887",
            "metadata": {},
            "outputs": [],
            "source": [
                "import onnx\n",
                "onnx_model = onnx.load(\"fox_word_predictor.onnx\")\n",
                "onnx.checker.check_model(onnx_model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "id": "cff2fa96",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "brown\n",
                        "fox\n",
                        "jumped\n"
                    ]
                }
            ],
            "source": [
                "import onnxruntime\n",
                "\n",
                "ort_session = onnxruntime.InferenceSession(\n",
                "    \"./fox_word_predictor.onnx\", providers=[\"CPUExecutionProvider\"]\n",
                ")\n",
                "\n",
                "def predict(phrase_input):\n",
                "    tensor_input = get_input_tensor(phrase_input)\n",
                "\n",
                "    onnxruntime_input = {\n",
                "        \"input\": tensor_input.numpy(),\n",
                "    }\n",
                "    output = ort_session.run(None, onnxruntime_input)\n",
                "\n",
                "    predicted_idx = np.argmax(output[0][0])\n",
                "    return index_to_word[predicted_idx]\n",
                "\n",
                "print(predict(\"the quick\"))\n",
                "print(predict(\"quick brown\"))\n",
                "print(predict(\"brown fox\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8de86677",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1584293",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
