{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d3664fc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vocabulary size: 8\n",
                        "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
                        " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
                        " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
                        " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
                        " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
                        " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
                        " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
                        " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "from torch import nn\n",
                "from torch import optim\n",
                "\n",
                "sentence = \"The quick brown fox jumped over the lazy dog\"\n",
                "\n",
                "unique_words = sorted(list(set([word.lower() for word in sentence.split()])))\n",
                "length = len(unique_words)\n",
                "word_to_index = {word: i for i, word in enumerate(unique_words)}\n",
                "index_to_word = {i: word for i, word in enumerate(unique_words)}\n",
                "\n",
                "vectors = []\n",
                "vector_template = np.zeros(length)\n",
                "\n",
                "for index, word in enumerate(unique_words):\n",
                "    vector = vector_template.copy()\n",
                "    vector[index] = 1\n",
                "    vectors.append(vector)\n",
                "\n",
                "vectors = np.array(vectors)\n",
                "print(f\"Vocabulary size: {length}\")\n",
                "print(vectors)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "d19e98bc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 100, Loss: 0.0351\n",
                        "Epoch 200, Loss: 0.0045\n",
                        "Epoch 300, Loss: 0.0016\n",
                        "Epoch 400, Loss: 0.0007\n",
                        "Epoch 500, Loss: 0.0004\n"
                    ]
                }
            ],
            "source": [
                "words = [word.lower() for word in sentence.split()]\n",
                "completions = [\n",
                "    {\n",
                "        \"x\": \"the quick\",\n",
                "        \"y\": \"brown\"\n",
                "    },\n",
                "    {\n",
                "        \"x\": \"quick brown\",\n",
                "        \"y\": \"fox\"\n",
                "    }\n",
                "]\n",
                "\n",
                "for i in range(2, len(words) - 2):\n",
                "    completions.append({\n",
                "        \"x\": f\"{words[i]} {words[i+1]}\",\n",
                "        \"y\": words[i+2]\n",
                "    })\n",
                "\n",
                "def get_input_tensor(text):\n",
                "    words = text.lower().split()\n",
                "    # Concatenate vectors for the two input words\n",
                "    # Each word vector is size 8 (length of vocab)\n",
                "    # Resulting tensor size is 16\n",
                "    input_vector = []\n",
                "    for word in words:\n",
                "        idx = word_to_index[word]\n",
                "        input_vector.extend(vectors[idx])\n",
                "    return torch.tensor(input_vector, dtype=torch.float32).unsqueeze(0) # Add batch dimension\n",
                "\n",
                "def get_target_index_tensor(target_word):\n",
                "    # CrossEntropyLoss expects class index, not one-hot vector\n",
                "    idx = word_to_index[target_word.lower()]\n",
                "    return torch.tensor([idx], dtype=torch.long)\n",
                "\n",
                "network = nn.Sequential(\n",
                "    nn.Linear(16, 8), # input layer\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8), # hidden layer 1\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(8, 8) \n",
                ")\n",
                "\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
                "\n",
                "epochs = 500\n",
                "for epoch in range(epochs):\n",
                "    total_loss = 0\n",
                "    for completion in completions:\n",
                "        input_tensor = get_input_tensor(completion[\"x\"])\n",
                "        target_tensor = get_target_index_tensor(completion[\"y\"])\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        output = network(input_tensor)\n",
                "        \n",
                "        loss = criterion(output, target_tensor)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "        \n",
                "    if (epoch + 1) % 100 == 0:\n",
                "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "prediction-cell",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predictions:\n",
                        "jumped over -> the\n",
                        "the quick -> brown\n",
                        "fox jumped -> over\n",
                        "over the -> lazy\n",
                        "\n",
                        "============ full sentence prediction ============\n",
                        "0 the quick\n",
                        "1 quick brown\n",
                        "2 brown fox\n",
                        "3 fox jumped\n",
                        "4 jumped over\n",
                        "5 over the\n",
                        "6 the lazy\n",
                        "the quick brown fox jumped over the lazy dog\n"
                    ]
                }
            ],
            "source": [
                "def predict(text):\n",
                "    network.eval()\n",
                "    with torch.no_grad():\n",
                "        input_tensor = get_input_tensor(text)\n",
                "        output_logits = network(input_tensor)\n",
                "        probabilities = torch.softmax(output_logits, dim=1)\n",
                "        predicted_idx = torch.argmax(probabilities).item()\n",
                "        return index_to_word[predicted_idx]\n",
                "\n",
                "# Test predictions\n",
                "print(\"Predictions:\")\n",
                "print(f\"jumped over -> {predict('jumped over')}\")\n",
                "print(f\"the quick -> {predict('the quick')}\")\n",
                "print(f\"fox jumped -> {predict('fox jumped')}\")\n",
                "print(f\"over the -> {predict('over the')}\")\n",
                "\n",
                "\n",
                "\n",
                "# Full sentence prediction\n",
                "print(\"\\n============ full sentence prediction ============\")\n",
                "full_sentence = \"the quick\"\n",
                "start = full_sentence\n",
                "\n",
                "for i in range(7):\n",
                "    print(i, start)\n",
                "    prediction = predict(start)\n",
                "    full_sentence = \" \".join(full_sentence.split() + [prediction])\n",
                "    start = \" \".join(full_sentence.split()[-2:])\n",
                "\n",
                "print(full_sentence)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
